{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f7075ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install diffusers\n",
    "!pip install transformers\n",
    "!pip install accelerate\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image # used to represent images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae9b325",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nDiffusionPipeline requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# a tool used to generate images using stable diffusion\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DiffusionPipeline\n\u001b[1;32m----> 3\u001b[0m generator \u001b[38;5;241m=\u001b[39m DiffusionPipeline\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompVis/stable-diffusion-v1-4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# specifies what GPUs should be used for this generation\u001b[39;00m\n\u001b[0;32m      5\u001b[0m generator\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\diffusers\\utils\\dummy_pt_objects.py:480\u001b[0m, in \u001b[0;36mDiffusionPipeline.from_pretrained\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 480\u001b[0m     requires_backends(\u001b[38;5;28mcls\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\diffusers\\utils\\import_utils.py:527\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m    525\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[1;32m--> 527\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVersatileDiffusionTextToImagePipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVersatileDiffusionPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    534\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnCLIPPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    535\u001b[0m ] \u001b[38;5;129;01mand\u001b[39;00m is_transformers_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.25.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    537\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to install `transformers>=4.25` in order to use \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m pip install\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m --upgrade transformers \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m```\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m     )\n",
      "\u001b[1;31mImportError\u001b[0m: \nDiffusionPipeline requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\n"
     ]
    }
   ],
   "source": [
    "# a tool used to generate images using stable diffusion\n",
    "from diffusers import DiffusionPipeline\n",
    "generator = DiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\")\n",
    "# specifies what GPUs should be used for this generation\n",
    "generator.to(\"cuda\")\n",
    "image = generator(\"A photo of a white lion in the jungle.\").images[0]\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68229e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = generator(\"A painting of a white lion in the style of Picasso.\").\n",
    "images[0]\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c491d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline used for image to image generation with stable diffusion\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "# loads a pretrained generator model\n",
    "generator = StableDiffusionImg2ImgPipeline.from_pretrained(\"runwayml/stablediffusion-\n",
    "v1-5\")\n",
    "# moves the generator model to the GPU (CUDA) for faster processing\n",
    "generator.to(\"cuda\")\n",
    "init_image = Image.open(\"landscape.jpg\")\n",
    "init_image.thumbnail((768, 768)) # resizes the image to prepare it as input of the model\n",
    "plt.imshow(init_image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e652f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a detailed prompt describing the desired visual\n",
    "# for the produced image\n",
    "prompt = \"A realistic mountain\n",
    "landscape with a large castle.\"\n",
    "image = generator(prompt=prompt,\n",
    "image = init_image, strength=0.75).\n",
    "images[0]\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053c0093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a new image based on the prompt and the\n",
    "# initial image using the generator model\n",
    "image = generator(prompt=prompt,\n",
    "image = init_image, strength=1).images[0]\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d110f336",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_image = Image.open(\"cat_1.jpg\")\n",
    "init_image.thumbnail((768, 768))\n",
    "plt.imshow(init_image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0489a6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A photo of a tiger\"\n",
    "image = generator(prompt=prompt, image=init_image, strength=0.5).images[0]\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = generator(prompt=prompt,\n",
    "image = init_image, strength=0.75).\n",
    "images[0]\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc549bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool used for text-guided image in-painting\n",
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "init_image = Image.open(\"cat_on_bench.png\").resize((512, 512))\n",
    "plt.imshow(init_image);\n",
    "mask_image = Image.open(\"cat_mask.jpg\").resize((512, 512))\n",
    "plt.imshow(mask_image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb952199",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = StableDiffusionInpaintPipeline.from_pretrained(\"runwayml/stablediffusion-\n",
    "inpainting\")\n",
    "generator = generator.to(\"cuda\")\n",
    "prompt = \"A photo of an astronaut\"\n",
    "image = generator(prompt=prompt, image=init_image, mask_image=mask_image).\n",
    "images[0]\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a709c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_image = Image.open(\"desk.jpg\").resize((512, 512))\n",
    "plt.imshow(init_image);\n",
    "mask_image = Image.open(\"desk_mask.jpg\").resize((512, 512))\n",
    "plt.imshow(mask_image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3599cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A photo of a book\"\n",
    "image = generator(prompt=prompt, image=init_image, mask_image=mask_image).\n",
    "images[0]\n",
    "plt.imshow(image);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
